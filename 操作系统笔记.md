https://github.com/flycash/interview-baguwen

# 为什么使用虚拟内存

- 虚拟内存可以结合磁盘和物理内存(可以想象内存和磁盘它都属于一整块虚拟内存)的优势为进程提供看起来速度足够快并且容量足够大的存储（**虚拟内存是操作系统物理内存和进程之间的中间层**，它为进程隐藏了物理内存这一概念 实现缓存机制 无法直接访问内存 都必须通过虚拟内存 即页表进行访问 如果发生缺页中断 如果页表没有虚拟内存当物理内存的对应关系就在页表建立关系 否则将磁盘中的数据加载到内存中，如果内存空间已满进行调页算法进行页面替换）；
- **虚拟内存可以为进程提供独立的内存空间**并引入多层的页表结构将虚拟内存翻译成物理内存，进程之间可以共享物理内存减少开销，也能简化程序的链接、装载以及内存分配过程（可以分配连续的虚拟内存 通过 内存管理单元（MMU）进行分配有可能不连续）；
- 虚拟内存可以控制进程对物理内存的访问 fork 或者进程间共享内存通过复制页表实现，隔离不同进程的访问权限（**读权限、写权限和执行权限**）（比如某些不可读内存，或者操作系统内存的数据结构），提高系统的安全性；

虚拟内存中的虚拟页（Virtual Page，PP）可能处于以下的三种状态 — 未分配（Unallocated）、未缓存（Uncached）和已缓存（Cached），其中未分配的内存页是没有被进程申请使用的，也就是空闲的虚拟内存，不占用虚拟内存磁盘的任何空间，未缓存和已缓存的内存页分别表示仅加载到磁盘中的内存页和已经加载到主存中的内存

虚拟内存可以为正在运行的进程提供独立的内存空间，制造一种每个进程的内存都是独立的假象，在 64 位的操作系统上，每个进程都会拥有 256 TiB 的内存空间，内核空间和用户空间分别占 128 TiB

![image-20210409182603950](C:\Users\liuxingguang\AppData\Roaming\Typora\typora-user-images\image-20210409182603950.png)



比如exec加载可执行文件时只创建页表映射，在执行过程中用到某一页触发缺页才将页从硬盘加载到内存中，按需加载而不是一开始全部从硬盘拷贝到内存里，更有助于理解虚拟地址空间的效果。

那虚拟内存是如何隔离各个进程空间的呢 各个进程会有独立的 Page Table 映射物理内存

go中切片访问元素快是因为内存连续，所以**寻址比较快**吧，物理内存连不连续应该不影响这个结果，访问虚拟内存的时候都需要做一次转换。

我们可以将虚拟内存看作是在磁盘上一片空间，当这片空间中的一部分访问比较频繁时，**该部分数据会以页为单位被缓存到主存中**以加速 CPU 访问数据的性能，虚拟内存利用空间较大的磁盘存储作为『内存』并使用主存储缓存进行加速，**让上层认为操作系统的内存很大而且很快，然而区域很大的磁盘并不快，而很快的内存也并不大**。

# **为什么使用4KB默认设置**

作为内存页大小 4KB 的内存页是上个世纪决定的默认设置（现在在其他操作系统也有实现更大的内存页）（末尾12位代表偏移量，剩下的 36 位会分四组分别表示当前层级在上一层中的索引）目前是四层页表项 如果更小则需要更多层页表项（五层或更多）

- 过小的页面大小会带来较大的页表项增加寻址时 TLB（Translation lookaside buffer）的查找时间和额外开销，但是也会减少程序中的内存碎片，提高内存的利用率；
- 过大的页面大小会浪费内存空间，造成内存碎片，降低内存的利用率（以及多进程共享内存时的写时复制影响额外开销），但是可以减少进程中的页表项以及 TLB 的寻址时间；

# 为什么 CPU 访问硬盘很慢

- CPU 需要通过 I/O 操作访问外部存储中的数据，**编程 I/O**（通过轮询的方式进行写入会占满cpu）、**中断驱动 I/O** （会将一部分任务给IO设备 如果写入好了会通过信号的方式来通知CPU 在之前cpu可以执行其他进程）和 **DMA（Direct Memory Access，直接内存存取）**（将字符全部写入DMA缓存中 有DMA再写入IO设备 **默认方式**） 几种方式都会带来额外开销并占用较多的 CPU 时间；
- 机械硬盘会通过机械结构访问其中存储的数据，每一次硬盘的随机 I/O 都需要执行队列、寻道、旋转和转移数据几个过程，大约需要消耗 10ms 的时间，尽量属于顺序 I/O 可以优化好几个数量级，SSD寻址不会通过机械设备读取由电路完成会快很多；

- 写入到硬盘上的数据一定会被持久存储，不会丢失吗？

  数据先落到Page Cache 然后调用fsync（）才能写道硬盘上

- 内存中的数据为什么在断电重启之后就会被清空？

  靠通电保持电位（数据）断电就重置了 硬盘通过磁力的方式进行持久化

# 为什么 NUMA 会影响程序的延迟

非一致性内存访问（Non-Uniform Memory Access、NUMA）是一种计算机内存的设计方式[1](https://draveness.me/whys-the-design-numa-performance#fn:1)，与 NUMA 相对的还有一致性内存访问（Uniform Memory Access、UMA），也被称作对称多处理器架构（Symmetric Multi-Processor、SMP），早期的计算机都会使用 SMP，然而现代的多数计算机都会采用 NUMA 架构管理 CPU 和内存资源。		多核架构限制在于前端总线 北桥 内存总线

![image-20210412172453579](C:\Users\liuxingguang\AppData\Roaming\Typora\typora-user-images\image-20210412172453579.png)

将内存与cpu绑定划分节点

![image-20210412172531813](C:\Users\liuxingguang\AppData\Roaming\Typora\typora-user-images\image-20210412172531813.png)

- NUMA 引入了本地内存和远程内存，**CPU 访问本地内存的延迟会小于访问远程内存**；
- NUMA 的  以及**CPU分配策略**  **内存分配策略**与内存回收策略结合时会可能会导致 Linux 的频繁交换分区（Swap）进而影响系统的稳定性，交换分区影响性能通过分配合理的策略可以优化 例如节点平均分配内存；

我们当然更希望**主机上的所有 CPU 都能够快速地访问全部的内存**，但是硬件的限制导致我们无法实现这么理想的情况，而 NUMA 可能是 CPU 架构发展的必然方向，通过将 CPU 和内存资源分组降低总线的压力，让单个主机容纳很多的 CPU。

# 为什么 HugePages 可以提升数据库性能

- HugePages （默认是2MB内存页 更大可以达到1GB）可以降低内存页面的管理开销，它可以减少进程中的页表项、提高 TLB 缓存的命中率和内存的访问效率；
- HugePages 可以锁定内存，禁止操作系统的内存交换和释放，不会被交换到磁盘上为其它请求让出内存；
- 适用于特定场景 如数据库 Hadoop全家桶等 对于普通web服务器可能是负担 同样在redis fork进行写时复制同样 在改动数据比较小HugePages会带来更大的开销

# 为什么 Linux 需要 Swapping

**物理内存和硬盘上的交换分区组成了操作系统上可用的虚拟内存**

先在空闲页列表中查找是否有可用的页面，如果不存在可用页面进行分配新的内存页

Linux 在**内存也不足**时获取内存的几个常见方法**：内存压缩、直接回收以及触发内存不足错误杀掉部分进程。**

应用程序在启动阶段使用的大量内存在启动后往往都不会使用，通过后台运行的守护进程，我们可以将这部分只使用一次的内存交换到磁盘上为其他内存的申请预留空间。

**kswapd会在空闲内存低于一定水位时，回收内存页中的空闲内存保证系统中的其他进程可以尽快获得申请的内存**

当系统内存不足时应该立即触发内存不足（Out of memory、OOM）并杀掉进程，但是 Swapping 其实为系统管理员提供了另外一种选择，利用磁盘的交换空间避免程序被直接退出，以**降低服务质量的代价换取服务的部分可用性**。Linux 中的 Swapping 机制主要是为**内存不足**和**内存闲置**两种常见的情况存在的 （**在可用性要求较高的场合，使用降级而不是停止服务的方式比较合适。**）

- Swapping 可以直接将进程中使用相对较少的页面换出内存：当系统需要的内存超过了可用的物理内存时，内核会将内存中不常使用的内存页交换到磁盘上为当前进程让出内存，保证正在执行的进程的可用性；
- Swapping 可以将进程中的闲置页面换出内存：应用程序在启动阶段使用的大量内存在启动后往往都不会使用，通过后台运行的守护进程，我们可以将这部分只使用一次的内存交换到磁盘上为其他内存申请预留空间；

**swapping和你之前的文章 `为什么 Linux 需要虚拟内存` 中的页面交换不是一个东西**

# 为什么基础服务不应该高可用

1. 在足够长的时间中，任何服务都没法保证 100% 可用，100% 可用更像是一个危险的承诺，一旦默认了这个假设就不利于我们构建高可用的服务；
2. 边际成本是提升可用性时必须要考虑的因素，作为服务提供商必须要衡量提升可用性的成本和收益，而过高或者过低的可用性都会降低总体的收益；
3. 服务的高可用从来都不来源于单一的依赖，只有使用更多异构的副本和组件才能尽可能保证服务的稳定；

例如：

- 物理机不同：部署在不同机器上的 Redis 服务；
- 协议和代码不同：本地部署的 Redis 和 memcached 服务；
- 服务提供商不同：谷歌云和 AWS 的 Redis 服务；
- 地理位置不同：北京和上海的机房中的 Redis 服务；
- …

如果可用性高于约定的 SLA，**很多服务提供商会在一个可用性计算周期结束之前故意动触发服务的宕机**

SRE: Google 运维解密 这本书也说了, 故意宕机一方面是让用户明白这些东西不是百分百可靠的, 然后通过自己的手段解决; 另一方面是为了不让用户的预期过高.

# 为什么使用通信来共享内存

『不要通过共享内存来通信，我们应该使用通信来共享内存』

​	channel底层同样使用的是共享内存和锁 更高级的抽象

![image-20210413110429966](C:\Users\liuxingguang\AppData\Roaming\Typora\typora-user-images\image-20210413110429966.png)

1. 首先，使用发送消息来同步信息相比于直接使用共享内存和互斥锁是一种更高级的抽象，使用更高级的抽象能够为我们在程序设计上提供更好的封装，让程序的逻辑更加清晰；
2. 其次，消息发送在解耦方面与共享内存相比也有一定优势，我们可以将线程的职责分成生产者和消费者，并**通过消息传递的方式将它们解耦，不需要再依赖共享内存**；
3. **最后，Go 语言选择消息发送的方式，通过保证同一时间只有一个活跃的线程能够访问数据，能够从设计上天然地避免线程竞争和数据冲突的问题；**

![image-20210413110902662](C:\Users\liuxingguang\AppData\Roaming\Typora\typora-user-images\image-20210413110902662.png)

不推荐或者禁止使用外键重启可能会出现主键问题 

# 为什么 MySQL 的自增主键不单调也不连续

> 主键连续的意义在哪里？充分利用防止用完？

连续的key可以保证b+树写索引的时候尽量顺序写，不会导致page页面分裂

- MySQL 5.7 版本之前在内存中存储 `AUTO_INCREMENT` 计数器，实例重启后会根据表中的数据重新设置，在删除记录后重启就可能出现重复的主键，该问题在 8.0 版本使用重做日志解决，保证了主键的单调性；
- MySQL 插入数据获取 `AUTO_INCREMENT` 时不会使用事务锁，而是会使用互斥锁，并发的插入事务可能出现部分字段冲突导致插入失败，想要保证主键的连续需要串行地执行插入语句；

> 有个问题想问下，关于图 3 - 5.7 版本之前的 AUTO_INCMRENT
>
> 那图上半部的意思是更新 `executions` 之后也会影响 `trades` 表的 `AUTO_INCMRENT` 的？

不是，这里的意思是 executions 表中的记录引用了 trades 表中 id 为 10 的记录，但是随后 trades 表中的记录被删除了，我们使用相同的 id 创建了新的记录，executions 表完全不知道，**它以为自己引用的还是过去的记录**。

- 不使用外键牺牲了数据库中数据的一致性，但是却能够减少数据库的负载；
- 模拟外键将一部分工作移到了数据库之外，我们可能需要放弃一部分一致性以获得更高的可用性，但是为了这部分可用性，我们会付出更多的研发与维护成本，也增加了与数据库之间的网络通信次数；
- 使用外键保证了数据库中数据的一致性，也将全部的计算任务全部交给了数据库；

大团队也有更多的时间和精力去设计其他的方案，例如：分布式的关系型数据库。

使用外键时可能遇到的问题：

- `RESTRICT` 外键会在更新和删除关系表中的数据时对外键约束的合法性进行检查，保证外键不会引用到不存在的记录；
- `CASCADE` 外键会在更新和删除关系表中的数据时触发对关联记录的更新和删除，在数据量较大的数据库中可能会有数量级的放大效果；

话说现在接触到的系统里都很少直接删除行数据了，都是用 `deleted` 或者 `deleted_at` 做归档化。



Mysql默认的事务隔离级别是**可重复读(Repeatable Read)**



当用户再次启动数据库进程时，还能够立刻通过查询回滚日志将之前未完成的事务进行回滚，这也就需要回滚日志必须先于数据持久化到磁盘上，是我们需要先写日志后写数据库的主要原因。

- **Undo** ：将所有没有提交的事务恢复到提交前的状态，因而 `(T, x, v)` 中 v 记录的是修改前的值，便于恢复。
- **Redo** ：将所有已提交的事务（已写入 log，但因为崩溃数据未写入）重新写入，因而 `(T, x, v)` 中 v 记录的是修改后的值，便于重做。

**并发控制通过读写锁和MVCC（多版本控制）结合**

MVCC 在于乐观锁结合时的实现上有一些不同，最终实现的叫做多版本时间戳排序协议（Multiversion Timestamp Ordering），在这个协议中，所有的事务在执行之前都会被分配一个唯一的时间戳，每一个数据项都有读写两个时间戳：

![image-20210415145948509](C:\Users\liuxingguang\AppData\Roaming\Typora\typora-user-images\image-20210415145948509.png)

事务发出了一个读请求，数据库直接将最新版本的数据返回，不会被任何操作阻塞，而写操作在执行时，事务的时间戳一定要大或者等于数据行的读时间戳，否则就会被回滚。

死锁：两个持有锁的资源相互请求 预防死锁通过抢占和回滚

幻读通过 mvcc 和 next-key lock解决（ 间隙锁和行锁合称 next-key lock，每个 next-key lock 是前开后闭区间）

连接池设多大 连接数 = ((核心数 * 2) + 有效磁盘数)



一个 SQL 执行的很慢，我们要分两种情况讨论：

1、大多数情况下很正常，偶尔很慢，则有如下原因

(1)、数据库在刷新脏页（内存不够 或者 内存页空闲 系统空闲），例如 redo log 写满了需要同步到磁盘。（先写redo log 再由redo log更新脏页）

**当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。**

(2)、执行的时候，遇到锁，如表锁、行锁。

2、这条 SQL 语句一直执行的很慢，则有如下原因。

(1)、没有用上索引：例如该字段没有索引；由于对字段进行运算、函数操作导致无法用索引。

(2)、数据库选错了索引。（用保存主键信息的辅助索引最后走的主键查询）

**规范：**

尽量使用Innodb作为存储引擎

避免使用text类型 枚举类型（效率低要使用额外操作）

尽可能把所有列定义为 NOT NULL（占用空间，null比较需要特殊处理）

使用预编译

不使用select  *

不要join太多表

尽量不使用外键（影响父表和子表的写操作从而降低性能）

不使用随机排序

大 sql 拆分

`count(*)`会遍历全表(没有where条件)，虽然结果准确，但会导致性能问题。

**不建议使用Text类型 （Text一个能够存储大量的数据的大对象 MySQL是单进程多线程模型 它不但消耗大量的网络和IO带宽，同时在该表上的DML操作都会变得很慢。 使用es存储 使用对象存储 阿里的oss 或 aws 的 s3）**

**建议将复杂的统计分析类的SQL，建议迁移到实时数仓OLAP中，例如目前使用比较多的clickhouse，里云的ADB，AWS的Redshift都可以，做到OLTP和OLAP类业务SQL分离，保证业务系统的稳定性。**

最常见的分区方法就是按照时间进行分区 



MySQL支持范围分区（RANGE），列表分区（LIST），哈希分区（HASH）以及KEY分区 **partion** 命令 

分库（读写分离）分表垂直拆分水平拆分 简单的通过%分表数

从锁定资源的角度来看，MySQL 中的锁分为：

- **表级锁**
- **行级锁**
- **页面锁**

表级锁：对整张表加锁。开销小，加锁快;不会出现死锁;锁定粒度大，发生锁冲突的概率最高，并发度最低。

行级锁：对某行记录加锁。开销大，加锁慢;会出现死锁;锁定粒度最小，发生锁冲突的概率最低，并发度也最高。

页面锁：开销和加锁时间界于表锁和行锁之间;会出现死锁;锁定粒度界于表锁和行锁之间，并发度一般。

在实际开发过程中，主要会使用到表级锁和行级锁两种

- MyISAM 存储引擎，它不支持事务、表锁设计，支持全文索引，主要面向一些在线分析处理(OLAP)数据库应用。说白了主要就是查询数据，对数据的插入，更新操作比较少。

### 使用 Explain 进行分析

Explain 用来分析 SELECT 查询语句，开发人员可以通过分析 Explain 结果来优化查询语句。

比较重要的字段有：id（执行顺序从上至下）

- select_type : 查询类型，有简单查询、联合查询、子查询等
- key : 使用的索引
- rows : 扫描的行数

# (2) explain参数详解

| id   | Columns       | JSON Name     | Meaning                                           |
| :--- | :------------ | :------------ | :------------------------------------------------ |
| 1    | id            | select_id     | 每个select子句的标识id                            |
| 2    | select_type   | None          | select语句的类型                                  |
| 3    | table         | table_name    | 当前表名                                          |
| 4    | partitions    | partitions    | 匹配的分区                                        |
| 5    | type          | access_type   | 当前表内访问方式 join type                        |
| 6    | possible_keys | possible_keys | 可能使用到的索引                                  |
| 7    | key           | key           | 经过优化器评估最终使用的索引                      |
| 8    | key_len       | key_length    | 使用到的索引长度                                  |
| 9    | ref           | ref           | 引用到的上一个表的列                              |
| 10   | rows          | rows          | rows_examined，要得到最终记录索要扫描经过的记录数 |
| 11   | filtered      | filtered      | 按表条件过滤行的百分比                            |
| 12   | Extra         | None          | 额外的信息说明                                    |

### 索引的优点(中大型表) 辅助索引（非聚簇索引）和主键索引（聚簇索引）

- 大大减少了服务器需要扫描的数据行数。
- 帮助服务器避免进行排序和分组，以及避免创建临时表（B+Tree 索引是有序的，可以用于 ORDER BY 和 GROUP BY 操作。临时表主要是在排序和分组过程中创建，不需要排序和分组，也就不需要创建临时表）。
- 将随机 I/O 变为顺序 I/O（B+Tree 索引是有序的，会将相邻的数据都存储在一起）。

### **劣势：**

- 索引也要动态的维护
- 索引会占据磁盘空间**
- **索引虽然会提高查询效率，但是会降低更新表的效率**。比如每次对表进行增删改操作，MySQL不仅要保存数据，还有保存或者更新对应的索引文件。

Timestamp记录时间效率高还各种兼容

一个表 可以有多个索引（PRIMARY KEY） 只能有一个主键

 每个InnoDB表都有一个聚簇索引（通过簇拥索引组织数据 不能为null）  ，聚簇索引使用B+树构建，叶子节点存储的数据是整行记录。一般情况下，聚簇索引等同于主键索引，当一个表没有创建主键索引时，InnoDB会自动创建一个ROWID字段来构建聚簇索引

根据在辅助索引树中获取的主键id，到主键索引树检索数据的过程称为**回表**查询。可以通过覆盖索引例如建立id age 联合索引查找 id可以不用回表 

覆盖索引使用实例

现在我创建了索引(username,age)，我们执行下面的 sql 语句

```
select username , age from user where username = 'Java' and age = 22
```

在查询数据的时候：要查询出的列在叶子节点都存在！所以就不用回表

**组合索引的最左前缀匹配原则：使用组合索引查询时，mysql会一直向右匹配直至遇到范围查询(>、<、between、like)就停止匹配。**

limit优化考虑加索引 like 利用**索引条件下推ICP**优化

**很长的字段，想做索引我们怎么去优化他呢？**

因为存在一个磁盘占用的问题，索引选取的越长，占用的磁盘空间就越大，相同的数据页能放下的索引值就越少，搜索的效率也就会越低。

我当时就回答了一个hash，把字段hash为另外一个字段存起来，每次校验hash就好了，hash的索引也不大。

我们都知道只要区分度过高，都可以，那我们可以采用倒序，或者删减字符串这样的情况去建立我们自己的区分度，不过大家需要注意的是，调用函数也是一次开销哟，这点当时没注意。

就比如本来是www.aobing@qq,com 其实前面的`www.`基本上是没任何区分度的，所有人的邮箱都是这么开头的，你一搜一大堆出来，放在索引还浪费内存，你可以substring()函数截取掉前面的，然后建立索引。

我们所有人的身份证都是区域开头的，同区域的人很多，那怎么做良好的区分呢？REVERSE（）函数翻转一下，区分度可能就高了。

这些操作都用到了函数，我就说一下函数的坑。

### 索引失效

使用 != 符号

违反最左前缀原则

范围查询右边的列

使用覆盖索引

以%开头的Like模糊查询

用or分割开的条件示例，name字段是索引列 ， 而createtime不是索引列，中间是  or进行连接是不走索引的 ：

### Mysql如何为表字段添加索引？？？

1.添加PRIMARY KEY（主键索引）

```
ALTER TABLE `table_name` ADD PRIMARY KEY ( `column` ) 
```

2.添加UNIQUE(唯一索引)

```
ALTER TABLE `table_name` ADD UNIQUE ( `column` ) 
```

3.添加INDEX(普通索引)

```
ALTER TABLE `table_name` ADD INDEX index_name ( `column` )
```

4.添加FULLTEXT(全文索引)

```
ALTER TABLE `table_name` ADD FULLTEXT ( `column`) 
```

5.添加多列索引

```
ALTER TABLE `table_name` ADD INDEX index_name ( `column1`, `column2`, `column3` )
```

避免冗余索引 如（name,city ）和（name ）这两个索引就是冗余索引 可以通过查询 sys 库的 `schema_redundant_indexes` 表来查看冗余索引

 where orderby 和 limit 与 索引优化： 联合索引让where和排序字段同时用上索引 

| 隔离级别 | 脏读 | 不可重复读 | 幻影读 |
| :------: | :--: | :--------: | :----: |
| 未提交读 |  √   |     √      |   √    |
|  提交读  |  ×   |     √      |   √    |
| 可重复读 |  ×   |     ×      |   √    |
| 可串行化 |  ×   |     ×      |   ×    |

### 锁类型

**共享锁（S Lock）**

允许事务读一行数据

**排他锁（X Lock）**

允许事务删除或者更新一行数据

**意向共享锁（IS Lock）**

事务想要获得一张表中某几行的共享锁

**意向排他锁**

事务想要获得一张表中某几行的排他锁

```
- select * from table where ? lock in share mode;
- select * from table where ? for update;
```

```
假设有个表单products ，里面有id 跟name 二个栏位，id 是主键。

例1: (明确指定主键，并且有此数据，row lock)

SELECT * FROM products WHERE id='3' FOR UPDATE;

例2: (明确指定主键，若查无此数据，无lock)

SELECT * FROM products WHERE id='-1' FOR UPDATE;

例2: (无主键，table lock)

SELECT * FROM products WHERE name='Mouse' FOR UPDATE;

例3: (主键不明确，table lock)

SELECT * FROM products WHERE id<>'3' FOR UPDATE;

例4: (主键不明确，table lock)

SELECT * FROM products WHERE id LIKE '3' FOR UPDATE;

注1: FOR UPDATE 仅适用于InnoDB，且必须在事务区块(s	tart sta/COMMIT)中才能生效。
```

#### 脏读

脏读指的是不同事务下，当前事务可以读取到另外事务未提交的数据。

#### 不可重复读

不可重复读指的是同一事务内多次读取同一数据集合，读取到的数据是不一样的情况。

Phantom Proble 是指在同一事务下，连续执行两次同样的 sql 语句可能返回不同的结果，第二次的 sql 语句可能会返回之前不存在的行。

幻影读是一种特殊的不可重复读问题。

fsync

### 需要几次IO 

100W数据大概需要三层 8（id）+8 （指针引用）16 byte 默认一页有16 kb 

相对于磁盘IO来说，内存的io消耗可以忽略不计。一般来说B+Tree的高度一般都在2-4层，MySQL的InnoDB存储引擎在设计时是将根节点常驻内存的，也就是说查找某一键值的行记录时最多只需要1~3次磁盘I/O操作（根节点的那次不算磁盘I/O）。

```
那什么情况下才会使用自适应Hash索引呢？如果某个数据经常会访问到，当满足一定条件的时候，就会将这个数据页的地址存放到Hash表中。这样下次查询的时候，就可以直接找到这个页面的所在位置。需要说明的是：
1）自适应哈希索引只保存热数据（经常被使用到的数据），并非全表数据。因此数据量并不会很大，可以让自适应Hash放到缓冲池中，也就是InnoDB buffer pool，进一步提升查找效率。

2）InnoDB中的自适应Hash相当于是“索引的索引”，采用Hash索引存储的是B+树索引中的页面的地址。这也就是为什么可以称自适应Hash为索引的索引。
采用自适应Hash索引目的是可以根据SQL的查询条件加速定位到叶子节点，特别是当B+树比较深的时候，通过自适应Hash索引可以提高数据的检索效率。
```



# Redis

### 分布式锁 

```
setnx aobing 加锁
expire aobing 设置过期
del aobing 删除锁
```

### bitmap（记录日活）布隆过滤器

0 代表不活跃 1 代表活跃

### （HyperLogLog）

比如我们在使用新闻客户端看新闻时，它会给我们不停地推荐新的内容，它每次推荐时要去重，去掉那些已经看过的内容。问题来了，新闻客户端推荐系统如何实现推送去重的？

### GeoHash

附近的人

坑：

sync的时候遇到了bgsave 这个时候cpu飙升 ，因为bgsave之后会做一个emptyDB这个时候做bgsave cow的机制就没了会重新加载整个RDB 然后就swap了。

 **SDS** 

（会记录字符串长度）的空间分配策略完全杜绝了发生缓冲区溢出的可能性： 当 SDS API 需要对 SDS 进行修改时， API 会先检查 SDS 的空间是否满足修改所需的要求， 如果不满足的话， API 会自动将 SDS 的空间扩展至执行修改所需的大小

表 2-1 C 字符串和 SDS 之间的区别   使用 SDS 来保存之前提到的特殊数据格式就没有任何问题， 因为 SDS 使用 `len` 属性的值而不是空字符来判断字符串是否结束

| C 字符串                                             | SDS                                                  |
| :--------------------------------------------------- | :--------------------------------------------------- |
| 获取字符串长度的复杂度为 O(N) 。                     | 获取字符串长度的复杂度为 O(1) 。                     |
| API 是不安全的，可能会造成缓冲区溢出。               | API 是安全的，不会造成缓冲区溢出。                   |
| 修改字符串长度 `N` 次必然需要执行 `N` 次内存重分配。 | 修改字符串长度 `N` 次最多需要执行 `N` 次内存重分配。 |
| 只能保存文本数据。                                   | 可以保存文本或者二进制数据。                         |
| 可以使用所有 `` 库中的函数。                         | 可以使用一部分 `` 库中的函数。                       |

**dict**（单链表头插法）

因为 `dictEntry` 节点组成的链表没有指向链表表尾的指针， 所以为了速度考虑， 程序总是将新节点添加到链表的表头位置（复杂度为 O(1)）， 排在其他已有节点的前面。（单线程的好处不用加锁处理线程安全 Java hashmap 实现尾插法 怕rehash过程中链表节点成环）

随着操作的不断执行， 哈希表保存的键值对会逐渐地增多或者减少， 为了让哈希表的负载因子（load factor）（# 负载因子 = 哈希表已保存节点数量 / 哈希表大小）维持在一个合理的范围之内， 当哈希表保存的键值对数量太多或者太少时， 程序需要对哈希表的大小进行相应的扩展或者收缩。以 2的倍数进行rehash

1. 当 `ht[0]` 包含的所有键值对都迁移到了 `ht[1]` 之后 （`ht[0]` 变为空表）， 释放 `ht[0]` ， 将 `ht[1]` 设置为 `ht[0]` ， 并在 `ht[1]` 新创建一个空白哈希表， 为下一次 rehash 做准备。

当以下条件中的任意一个被满足时， 程序会自动开始对哈希表执行扩展操作：

1. 服务器目前没有在执行 BGSAVE 命令或者 BGREWRITEAOF 命令， 并且哈希表的负载因子大于等于 `1` ；
2. 服务器目前正在执行 BGSAVE 命令或者 BGREWRITEAOF 命令， 并且哈希表的负载因子大于等于 `5` ；（生成子进程 采用写时复制，避免不必要内存写入 减少内存浪费）

当负载因子小于 0.1 时进行收缩

采用渐近式hash 避免rehash对服务性能造成比较大的影响 会维持两个hash表 在每次增删改查过程中进行迁移会维持一个rehash索引 索引为-1时间就结束了 （添加新键都在新表中 其他操作会在两个表进行查找）

跳跃表（二分的方式进行查找）

**后退指针**

节点的后退指针（`backward` 属性）用于从表尾向表头方向访问节点： 跟可以一次跳过多个节点的前进指针不同， 因为每个节点只有一个后退指针， 所以每次只能后退至前一个节点。

列表对象的编码可以是 `ziplist` 或者 `linkedlist` 

哈希对象的编码可以是 `ziplist` （当键值对的字符串长度 或键值对的数量在一个较小的阈值）或者 `hashtable` 

- 保存了同一键值对的两个节点总是紧挨在一起， 保存键的节点在前， 保存值的节点在后；
- 先添加到哈希对象中的键值对会被放在压缩列表的表头方向， 而后来添加到哈希对象中的键值对会被放在压缩列表的表尾方向。

### sortset

`ziplist` 编码的有序集合对象使用压缩列表作为底层实现， 每个集合元素使用两个紧挨在一起的压缩列表节点来保存， 第一个节点保存元素的成员（member）， 而第二个元素则保存元素的分值（score）。

压缩列表内的集合元素按分值从小到大进行排序， 分值较小的元素被放置在靠近表头的方向， 而分值较大的元素则被放置在靠近表尾的方向。

因为以上原因， 为了让有序集合的查找和范围型操作都尽可能快地执行， Redis 选择了同时使用字典和跳跃表两种数据结构来实现有序集合。

服务器配置 `appendfsync` 选项的值直接决定 AOF 持久化功能的效率和安全性。

当 `appendfsync` 的值为 `always` 时， 服务器在每个事件循环都要将 `aof_buf` 缓冲区中的所有内容写入到 AOF 文件， 并且同步 AOF 文件， 所以 `always` 的效率是 `appendfsync` 选项三个值当中最慢的一个， 但从安全性来说， `always` 也是最安全的， 因为即使出现故障停机， AOF 持久化也只会丢失一个事件循环中所产生的命令数据。

当 `appendfsync` 的值为 `everysec` 时， 服务器在每个事件循环都要将 `aof_buf` 缓冲区中的所有内容写入到 AOF 文件， 并且每隔超过一秒就要在子线程中对 AOF 文件进行一次同步： 从效率上来讲， `everysec` 模式足够快， 并且就算出现故障停机， 数据库也只丢失一秒钟的命令数据。、

### 事务

![image-20210427145931793](C:\Users\liuxingguang\AppData\Roaming\Typora\typora-user-images\image-20210427145931793.png)

Redis 事务保证了其中的一致性（C）和隔离性（I），但并不保证原子性（A）和持久性（D）。

```
redis> MULTI
OK

redis> SET book-name "Mastering C++ in 21 days"
QUEUED

redis> GET book-name
QUEUED

redis> SADD tag "C++" "Programming" "Mastering Series"
QUEUED

redis> SMEMBERS tag
QUEUED

redis> EXEC
```

### 原子性（Atomicity）

单个 Redis 命令的执行是原子性的，但 Redis 没有在事务上增加任何维持原子性的机制，所以 Redis 事务的执行并不是原子性的。

如果一个事务队列中的所有命令都被成功地执行，那么称这个事务执行成功。

另一方面，如果 Redis 服务器进程在执行事务的过程中被停止 —— 比如接到 KILL 信号、宿主机器停机，等等，那么事务执行失败。

当事务失败时，Redis 也不会进行任何的重试或者回滚动作。

### 持久性

在内存中无法实现

### LUA

```
EVAL 命令
```

### 消息队列

消息队列 是指利用 高效可靠 的 消息传递机制 进行与平台无关的 数据交流，并基于数据通信来进行分布式系统的集成。

通过提供 消息传递 和 消息排队 模型，它可以在 分布式环境 下提供 应用解耦、弹性伸缩、冗余存储、流量削峰、异步通信、数据同步 等等功能

现在回顾下，我们使用的消息队列，一般都有什么样的特点：

- 三个角色：生产者、消费者、消息处理中心
- 异步处理模式：生产者 将消息发送到一条 虚拟的通道(消息队列)上，而无须等待响应。消费者 则 订阅 或是 监听 该通道，取出消息。两者互不干扰，甚至都不需要同时在线，也就是我们说的 松耦合
- 可靠性：消息要可以保证不丢失、不重复消费、有时可能还需要顺序性的保证

**二、Redis 实现消息队列**

思来想去，只有 List 和 Streams 两种数据类型，可以实现消息队列的这些需求，当然，Redis 还提供了发布、订阅(pub/sub) 模式。

### 脑裂

恰巧整个集群一分为二，然后两边各有一个主节点，然后都认为自己是主节点，而且从节点数也达标。这时候，如果将参数设置为超过一半，那么就可以避免这个问题。

### Redis Cluster

Redis 提供了槽迁移的命令，主要步骤就是让目标节点准备好接收，源节点准备迁移。热后小批量迁移key。

（讨论迁移过程中key的访问） 因此在迁移过程中，一个槽的部分 key 可能在源节点，一部分在目标节点。因此如果请求过来，打到源节点，源节点发现已经迁移了，就会返回一个 ASK 错误，这个错误会引导客户端直接去访问目标节点。

### 使用 Redis 来作为分布式锁，会有什么问题？

分析：这是一个很偏门冷僻的问题，在分布式锁里面可能会问到。我们假定你能正确使用 Redis 命令来写一个分布式锁，那么你还需要考虑这个场景：一个线程抢到了分布式锁，然后这个锁没有持久化，然后 Redis 崩了，很快又重启了，结果下一个线程立马就拿到了锁，这个时候就会出现你代码万无一失，但是分布式锁还是被多个线程拿到了的问题。我感觉很少人会考虑这个点，就暂且留着。

答案：要考虑分布式锁持久化的问题。假定我一个线程拿到了分布式锁，那么如果这个锁没有被持久化，那么如果 Redis 崩溃立刻重启，那么下一个线程立马就能拿到锁。

所以在考虑这种场景下，万无一失的方案，就是开启 AOF 持久化，并且将刷盘时机设置成`always`。

Redis 采用的是 IO 多路复用模型，核心分成四个组件：

1. 多路复用程序
2. 套接字队列
3. 事件分派器
4. 事件处理器。事件处理器又可以分成三种，连接处理器，请求处理器，回复处理器。

（事件处理器怎么记住这三个呢？按照“发起连接——发送请求——发回响应”三个步骤，刚好对应三个处理器）

（大概描述一下各个组件是怎么配合的，大致就是生产者——消费者模式）

多路复用程序会监听不同套接字的事件，当某个事件，比如发来了一个请求，那么多路复用程序就把这个套接字丢过去套接字队列，事件分派器从队列里边找到套接字，丢给对应的事件处理器处理。

[![Redis IO 多路复用](https://camo.githubusercontent.com/281bc3b567589cfa4be5d5546818f83864b35155367680060639dd9b74228f6f/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f32303230303631343139303834323633382e706e673f782d6f73732d70726f636573733d696d6167652f77617465726d61726b2c747970655f5a6d46755a33706f5a57356e6147567064476b2c736861646f775f31302c746578745f6148523063484d364c7939696247396e4c6d4e7a5a473475626d56304c314e6c61336c665a6d56702c73697a655f31362c636f6c6f725f4646464646462c745f3730)](https://camo.githubusercontent.com/281bc3b567589cfa4be5d5546818f83864b35155367680060639dd9b74228f6f/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f32303230303631343139303834323633382e706e673f782d6f73732d70726f636573733d696d6167652f77617465726d61726b2c747970655f5a6d46755a33706f5a57356e6147567064476b2c736861646f775f31302c746578745f6148523063484d364c7939696247396e4c6d4e7a5a473475626d56304c314e6c61336c665a6d56702c73697a655f31362c636f6c6f725f4646464646462c745f3730)

（扩展点一，讨论 6.0 引入的多线程模型）

Redis 这种模型的瓶颈在于从套接字中读写数据。因此在 6.0 中引入了异步 IO 线程，专门负责读取 IO 数据。在这种模型之下，相当于主线程监听到套接字事件，找到一个 IO 线程去读数据，之后主线程根据命令，找到对应的事件处理器，执行命令。写入响应的时候，也是交给了 IO 线程。这就是相当于，有一个线程池，只负责读写数据，主线程负责轮询和执行命令。

# 热key的危害

1.流量集中，达到物理网卡上限，影响其他key的访问。

2.请求过多，缓存分片服务被打垮，不能通过扩容解决,且不能发挥集群多分片的优势。

3.缓存击穿，可能打到DB,引起业务雪崩。

# 如何找到热key？

1.凭借业务经验，进行预估哪些是热key

2.客户端统计收集，本地统计或者上报 redis 命令 hotkeys

3.如果服务端有代理层，可以在代理层进行收集上报

# 如何解决热key问题？

1.增加分片副本，分担读流量

2.热key备份，比如key，备份为key1,key2……keyN，同样的数据N个备份，N个备份分布到不同分片，访问时可随机访问N个备份中的一个,进一步分担读流量

3.使用本地缓存，发现热key后，将热key对应数据加载到应用服务器本地缓存中，访问热key数据时，直接从本地缓存中获取，而不会请求到redis服务器。

4.用redis自带命令 redis-cli的热点key发现功能，执行redis-cli时加上–hotkeys选项即可。

5.自己抓包评估

pika



# 为什么 OLAP 需要列式存储

(主要是记录存取)

- 列式存储可以满足快速读取特定列的需求，在线分析处理往往需要在上百列的宽表中读取指定列分析，而传统的行式存储在分析数据时往往需要使用索引或者遍历整张表，带来了非常大的额外开销；
- 列式存储就近存储同一列的数据（例如字符串 数字等都存取在同一列），使用压缩算法可以得到更高的压缩率，减少存储占用的磁盘空间，虽然带来了 CPU 时间的额外开销，但是节省的 I/O 时间比带来的额外开销更多；

# 为什么比特币可以防篡改

- 非对称加密可以保证攻击者无法伪造账户所有者的签名；
- 共识算法可以保证网络中的历史交易不会被攻击者替换；

## 分布式一致性

在一个分布式系统中，如何保证集群中所有节点中的数据完全相同并且能够对某个提案（Proposal）达成一致是分布式系统正常工作的核心问题，而共识算法就是用来保证分布式系统一致性的方法。

着节点数量的增加，节点失效、故障或者宕机就变成了一件非常常见的事情，解决分布式系统中的各种边界条件和意外情况也增加了解决分布式一致性问题的难度。节点之间的网络通信收到干扰甚至阻断以及分布式系统的运行速度的差异都是解决分布式系统一致性所面临的难题。

异步的网络模型中，所有的节点由于没有时钟仅仅能根据接收到的消息作出判断，这时完全不能同时保证一致性、可用性和分区容错性，每一个系统只能在这三种特性中选择两种。

最终一致性允许多个节点的状态出现冲突，但是所有能够沟通的节点都能够在有限的时间内解决冲突，从不一致的状态恢复到一致，这里列出的两个条件比较重要，一是节点直接可以**正常通信**，二是冲突需要在**有限的时间**内解决，只有在这两个条件成立时才能达到最终一致性。

拜占庭将军问题是 分布式领域中最复杂、最严格的容错模型。

在该模型下，系统不会对集群中的节点做任何的限制，它们可以向其他节点发送随机数据、错误数据，也可以选择不响应其他节点的请求，

不要浪费时间去为异步分布式系统设计在任意场景上都能够实现共识的算法，异步系统完全没有办法保证能在有限时间内达成一致，在这里作者并不会尝试去证明 FLP 不可能定理

Paxos 和 Raft 是目前分布式系统领域中两种非常著名的解决一致性问题的共识算法，两者都能解决分布式系统中的一致性问题目前的**完备的**共识算法包括 Raft 本质上都是 Paxos 的变种。

技术人员还是要保持对技术的**敬畏心**，你不能**浅尝即止**，还是要深究的。

# Golang

map 底层实现

Go 语言使用拉链法来解决哈希碰撞的问题实现了哈希表，它的访问、写入和删除等操作都在编译期间转换成了运行时的函数或者方法。哈希在每一个桶中存储键对应哈希的前 8 位，当对哈希进行操作时，这些 `tophash` 就成为可以帮助哈希快速遍历桶中元素的缓存。

哈希表的每个桶都只能存储 8 个键值对，一旦当前哈希的某个桶超出 8 个，新的键值对就会存储到哈希的溢出桶中。随着键值对数量的增加，溢出桶的数量和哈希的装载因子也会逐渐升高，超过一定范围就会触发扩容，扩容会将桶的数量翻倍，元素再分配的过程也是在调用写操作时增量进行的，不会造成性能的瞬时巨大抖动。

### (3)协程来提高CPU利用率 

1.2之后开始基于协作式抢占 1.4 基于信号抢占 抢占式调度也只会在垃圾回收扫描任务时触发

1. 某些 Goroutine 可以长时间占用线程，造成其它 Goroutine 的饥饿；
2. 垃圾回收需要暂停整个程序（Stop-the-world，STW），最长可能需要几分钟的时间[6](https://draveness.me/golang/docs/part3-runtime/ch06-concurrency/golang-goroutine/#fn:6)，导致整个程序无法工作；

多进程、多线程已经提高了系统的并发能力，但是在当今互联网高并发场景下，为每个任务都创建一个线程是不现实的，因为会消耗大量的内存(进程虚拟内存会占用4GB[32位操作系统], 而线程也要大约4MB)。

大量的进程/线程出现了新的问题

- 高内存占用
- 调度的高消耗CPU

好了，然后工程师们就发现，其实一个线程分为“内核态“线程和”用户态“线程。

一个“用户态线程”必须要绑定一个“内核态线程”，但是CPU并不知道有“用户态线程”的存在，它只知道它运行的是一个“内核态线程”(Linux的PCB进程控制块)。

只有几kb只需要切换寄存器状态 最大1w但是一般设置p GOMAXPROCS()为cpu数的一半



早期GM模型需要锁抢占 现在为协作关系

> #### N:1关系

N个协程绑定1个线程，优点就是**协程在用户态线程即完成切换，不会陷入到内核态，这种切换非常的轻量快速**。但也有很大的缺点，1个进程的所有协程都绑定在1个线程上

缺点：

- 某个程序用不了硬件的多核加速能力
- 一旦某协程阻塞，造成线程阻塞，本进程的其他协程都无法执行了，根本就没有并发的能力了。

[![img](https://github.com/aceld/golang/raw/main/images/10-N-1%E5%85%B3%E7%B3%BB.png)](https://github.com/aceld/golang/blob/main/images/10-N-1关系.png)

> #### 1:1 关系

1个协程绑定1个线程，这种最容易实现。协程的调度都由CPU完成了，不存在N:1缺点，

缺点：

- 协程的创建、删除和切换的代价都由CPU完成，有点略显昂贵了。

[![img](https://github.com/aceld/golang/raw/main/images/11-1-1.png)](https://github.com/aceld/golang/blob/main/images/11-1-1.png)

> #### M:N关系

M个协程绑定1个线程，是N:1和1:1类型的结合，克服了以上2种模型的缺点，但实现起来最为复杂。

[![img](https://github.com/aceld/golang/raw/main/images/12-m-n.png)](https://github.com/aceld/golang/blob/main/images/12-m-n.png)

 协程跟线程是有区别的，线程由CPU调度是抢占式的，**协程由用户态调度是协作式的**，一个协程让出CPU后，才执行下一个协程。N:1关系

N个协程绑定1个线程，优点就是**协程在用户态线程即完成切换，不会陷入到内核态，这种切换非常的轻量快速**。但也有很大的缺点，1个进程的所有协程都绑定在1个线程上

缺点：

- 某个程序用不了硬件的多核加速能力
- 一旦某协程阻塞，造成线程阻塞，本进程的其他协程都无法执行了，根本就没有并发的能力了。

[![img](https://github.com/aceld/golang/raw/main/images/10-N-1%E5%85%B3%E7%B3%BB.png)](https://github.com/aceld/golang/blob/main/images/10-N-1关系.png)

> #### 1:1 关系

1个协程绑定1个线程，这种最容易实现。协程的调度都由CPU完成了，不存在N:1缺点，

缺点：

- 协程的创建、删除和切换的代价都由CPU完成，有点略显昂贵了。

[![img](https://github.com/aceld/golang/raw/main/images/11-1-1.png)](https://github.com/aceld/golang/blob/main/images/11-1-1.png)

> #### M:N关系

M个协程绑定1个线程，是N:1和1:1类型的结合，克服了以上2种模型的缺点，但实现起来最为复杂。

[![img](https://github.com/aceld/golang/raw/main/images/12-m-n.png)](https://github.com/aceld/golang/blob/main/images/12-m-n.png)

 协程跟线程是有区别的，线程由CPU调度是抢占式的，**协程由用户态调度是协作式的**，一个协程让出CPU后，才执行下一个协程。****

共经历三个过程：先从本地队列找，定期会从全局队列找，最后实在没办法，就去别的 P 偷。如下图所示：

![img](https://user-images.githubusercontent.com/7698088/63647181-f21f6b80-c74f-11e9-9c67-4267e8fb5c87.png)

![image-20210420111929689](C:\Users\liuxingguang\AppData\Roaming\Typora\typora-user-images\image-20210420111929689.png)



从上图我们可以分析出几个结论：

 1、我们通过 go func()来创建一个goroutine；

 2、有两个存储G的队列，一个是局部调度器P的本地队列、一个是全局G队列。新创建的G会先保存在P的本地队列中，如果P的本地队列已经满了就会保存在全局的队列中；

 3、G只能运行在M中，一个M必须持有一个P，M与P是1：1的关系。M会从P的本地队列弹出一个可执行状态的G来执行，如果P的本地队列为空，就会想其他的MP组合偷取一个可执行的G来执行；

 4、一个M调度G执行的过程是一个循环机制；

 5、当M执行某一个G时候如果发生了syscall或则其余阻塞操作，M会阻塞，如果当前有一些G在执行，runtime会把这个线程M从P中摘除(detach)，然后再创建一个新的操作系统的线程(如果有空闲的线程可用就复用空闲线程)来服务于这个P；

 6、当M系统调用结束时候，这个G会尝试获取一个空闲的P执行，并放入到这个P的本地队列。如果获取不到P，那么这个线程M变成休眠状态， 加入到空闲线程中，然后这个G会被放入全局队列中。

![image-20210420112427613](C:\Users\liuxingguang\AppData\Roaming\Typora\typora-user-images\image-20210420112427613.png)

也会经历如上图所示的过程：

1. runtime创建最初的线程m0和goroutine g0，并把2者关联。
2. 调度器初始化：初始化m0、栈、垃圾回收，以及创建和初始化由GOMAXPROCS个P构成的P列表。
3. 示例代码中的main函数是`main.main`，`runtime`中也有1个main函数——`runtime.main`，代码经过编译后，`runtime.main`会调用`main.main`，程序启动时会为`runtime.main`创建goroutine，称它为main goroutine吧，然后把main goroutine加入到P的本地队列。
4. 启动m0，m0已经绑定了P，会从P的本地队列获取G，获取到main goroutine。
5. G拥有栈，M根据G中的栈信息和调度信息设置运行环境
6. M运行G
7. G退出，再次回到M获取可运行的G，这样重复下去，直到`main.main`退出，`runtime.main`执行Defer和Panic处理，或调用`runtime.exit`退出程序。

调度器的生命周期几乎占满了一个Go程序的一生，`runtime.main`的goroutine执行之前都是为调度器做准备工作，`runtime.main`的goroutine运行，才是调度器的真正开始，直到`runtime.main`结束而结束。

![image-20210420123352132](C:\Users\liuxingguang\AppData\Roaming\Typora\typora-user-images\image-20210420123352132.png)

为什么要让m3和m4自旋，自旋本质是在运行，线程在运行却没有执行G，就变成了浪费CPU. 为什么不销毁现场，来节约CPU资源。因为创建和销毁CPU也会浪费时间，我们**希望当有新goroutine创建时，立刻能有M运行它**，如果销毁再新建就增加了时延，降低了效率。当然也考虑了过多的自旋线程是浪费CPU，所以系统中最多有`GOMAXPROCS`个自旋的线程(当前例子中的`GOMAXPROCS`=4，所以一共4个P)，多余的没事做线程会让他们休眠。

![image-20210420123416522](C:\Users\liuxingguang\AppData\Roaming\Typora\typora-user-images\image-20210420123416522.png)

### Golang编译器得逃逸分析（外部函数使用了子函数的局部变量）

 go语言编译器会自动决定把一个变量放在栈还是放在堆，编译器会做**逃逸分析(escape analysis)**，**当发现变量的作用域没有跑出函数范围，就可以在栈上，反之则必须分配在堆**。

我们得出了指针**必然发生逃逸**的三种情况（go version go1.13.4 darwin/amd64)：

- 在某个函数中new或字面量创建出的变量，将其指针作为函数返回值，则该变量一定发生逃逸（构造函数返回的指针变量一定逃逸）；
- 被已经逃逸的变量引用的指针，一定发生逃逸；
- 被指针类型的slice、map和chan引用的指针，一定发生逃逸；

- **在方法内把局部变量指针返回** 局部变量原本应该在栈中分配，在栈中回收。但是由于返回时被外部引用，因此其生命周期大于栈，则溢出。
- **发送指针或带有指针的值到 channel 中。** 在编译时，是没有办法知道哪个 goroutine 会在 channel 上接收数据。所以编译器没法知道变量什么时候才会被释放。
- **在一个切片上存储指针或带指针的值。** 一个典型的例子就是 []*string 。这会导致切片的内容逃逸。尽管其后面的数组可能是在栈上分配的，但其引用的值一定是在堆上。
- **slice 的背后数组被重新分配了，因为 append 时可能会超出其容量( cap )。** slice 初始化的地方在编译时是可以知道的，它最开始会在栈上分配。如果切片背后的存储要基于运行时的数据进行扩充，就会在堆上分配。
- **在 interface 类型上调用方法。** 在 interface 类型上调用方法都是动态调度的 —— 方法的真正实现只能在运行时知道。想像一个 io.Reader 类型的变量 r , 调用 r.Read(b) 会使得 r 的值和切片b 的背后存储都逃逸掉，所以会在堆上分配。

同时我们也得出一些**必然不会逃逸**的情况：

- 指针被未发生逃逸的变量引用；
- 仅仅在函数内对变量做取址操作，而未将指针传出；

有一些情况**可能发生逃逸，也可能不会发生逃逸**：

- 将指针作为入参传给别的函数；这里还是要看指针在被传入的函数中的处理过程，如果发生了上边的三种情况，则会逃逸；否则不会逃逸；

go build -gcflags=-m main.go   noescape

**对于未发生逃逸的变量，则直接在栈上分配内存。因为栈上内存由在函数返回时自动回收，因此能减小gc压力。**

## Go 常见内存泄漏的情况

Go程序可能会在一些情况下造成内存泄漏。[go101网站](https://go101.org/article/memory-leaking.html)总结了各种内存泄漏的情况，我在这里简单罗列一下：

- 获取长字符串中的一段导致长字符串未释放
- 同样，获取长slice中的一段导致长slice未释放
- 在长slice新建slice导致泄漏
- goroutine泄漏
- time.Ticker未关闭导致泄漏
- Finalizer导致泄漏
- Deferring Function Call导致泄漏

### make与new的异同

相同

- 堆空间分配

不同

make: 只用于slice、map以及channel的初始化， 无可替代 返回类型本身（本身为指针类型）

new: 用于类型内存分配（返回类型的指针并初始化零值）， 不常用

> new不常用
>
> 所以有new这个内置函数，可以给我们分配一块内存让我们使用，但是现实的编码中，它是不常用的。我们通常都是采用短语句声明以及结构体的字面量达到我们的目的，比如：
>
> ```
> i : =0
> u := user{}
> ```

> make 无可替代
>
> 我们在使用slice、map以及channel的时候，还是要使用make进行初始化，然后才才可以对他们进行操作。

### 哪些值可以使用，哪些值不能使用其地址？

我们无法采用以下值的地址：

- 字符串中的字节
- 地图元素
- 接口值的动态值（由类型断言公开）
- 常量值（包括命名常量和文字）
- 包级功能
- 方法（用作函数值）
- 中间值
  - 函数调用
  - 明确的价值转换
  - 各种操作，不包括指针取消引用操作，但包括：
    - 频道接收操作
    - 子字符串操作
    - 子切片操作
    - 加，减，乘，除等。

请注意，`&T{}`Go中有一个语法糖，。这是的简写形式`tmp := T{}; (&tmp)`。但是，尽管`&T{}`合法，但字面`T{}`量仍然无法寻址。



可以使用以下值的地址：

- 变数
- 可寻址结构的字段
- 可寻址数组的元素
- 切片的元素（切片是否可寻址）
- 指针取消引用操作



### 为什么地图元素无法寻址？

第一个原因是它会与地图的内部内存管理过程发生冲突。

####  插入屏障

`具体操作`: 在A对象引用B对象的时候，B对象被标记为灰色。(将B挂在A下游，B必须被标记为灰色)

`满足`: **强三色不变式**. (不存在黑色对象引用白色对象的情况了， 因为白色会强制变成灰色)

#### 强-弱” 三色不变式

- 强三色不变式

不存在黑色对象引用到白色对象的指针。

[![img](https://github.com/aceld/golang/raw/main/images/60-%E4%B8%89%E8%89%B2%E6%A0%87%E8%AE%B0%E9%97%AE%E9%A2%986.jpeg)](https://github.com/aceld/golang/blob/main/images/60-三色标记问题6.jpeg)

- 弱三色不变式

所有被黑色对象引用的白色对象都处于灰色保护状态.

[![img](https://github.com/aceld/golang/raw/main/images/61-%E4%B8%89%E8%89%B2%E6%A0%87%E8%AE%B0%E9%97%AE%E9%A2%987.jpeg)](https://github.com/aceld/golang/blob/main/images/61-三色标记问题7.jpeg)

#### (3) 删除屏障

`具体操作`: 被删除的对象，如果自身为灰色或者白色，那么被标记为灰色。

`满足`: **弱三色不变式**. (保护灰色对象到白色对象的路径不会断)

**黑色对象的内存槽有两种位置, `栈`和`堆`. 栈空间的特点是容量小,但是要求相应速度快,因为函数调用弹出频繁使用, 所以“插入屏障”机制,在栈空间的对象操作中不使用. 而仅仅使用在堆空间对象的操作中.**

GoV1.3- 普通标记清除法，整体过程需要启动STW，效率极低。

GoV1.5- 三色标记法， 堆空间启动写屏障，栈空间不启动，全部扫描之后，需要重新扫描一次栈(需要STW)，效率普通

GoV1.8-三色标记法，混合写屏障机制， 栈空间不启动，堆空间启动。整个过程几乎不需要STW，效率较高。

### 知识点1：defer的执行顺序

多个defer出现的时候，**它是一个“栈”的关系，也就是先进后出**。一个函数中，写在前面的defer会比写在后面的defer调用的晚。

**return之后的语句先执行，defer后的语句后执行**

**只要声明函数的返回值变量名称，就会在函数初始化时候为之赋值为0，而且在函数体作用域可见**。

我们知道，能够触发defer的是遇见return(或函数体到末尾)和遇见panic。

**panic仅有最后一个可以被revover捕获**。

**结构体比较**

> **结构体比较规则注意1**：只有相同类型的结构体才可以比较，结构体是否相同不但与属性类型个数有关，还与属性顺序相关.





## **总结一下操作 channel 的结果：**

| 操作     | nil channel | closed channel     | not nil, not closed channel                                  |
| -------- | ----------- | ------------------ | ------------------------------------------------------------ |
| close    | panic       | panic              | 正常关闭                                                     |
| 读 <- ch | 阻塞        | 读到对应类型的零值 | 阻塞或正常读取数据。缓冲型 channel 为空或非缓冲型 channel 没有等待发送者时会阻塞 |
| 写 ch <- | 阻塞        | panic              | 阻塞或正常写入数据。非缓冲型 channel 没有等待接收者或缓冲型 channel buf 满时会被阻塞 |

总结一下，发生 panic 的情况有三种：向一个关闭的 channel 进行写操作；关闭一个 nil 的 channel；重复关闭一个 channel。

读、写一个 nil channel 都会被阻塞。

# 空读写阻塞，写关闭异常（panic），读关闭空零。关闭上面两种情况都会 panic

```
package main

import (
	"sync"
)

const N = 10

var wg = &sync.WaitGroup{}

func main() {

    for i:= 0; i< N; i++ {
        wg.Add(1)
        go func(i int) {
            println(i)
            defer wg.Done()
        }(i)
    }

    wg.Wait()
}
```

切片扩容

```
在分配内存空间之前需要先确定新的切片容量，运行时根据切片的当前容量选择不同的策略进行扩容：

1. 如果期望容量大于当前容量的两倍就会使用期望容量；
2. 如果当前切片的长度小于 1024 就会将容量翻倍；
3. 如果当前切片的长度大于 1024 就会每次增加 25% 的容量，直到新容量大于期望容量；

上述代码片段仅会确定切片的大致容量，下面还需要根据切片中的元素大小对齐内存，当数组中元素所占的字节大小为 1、8 或者 2 的倍数时
```

map 扩容

```
装载因子已经超过 6.5；
哈希使用了太多溢出桶；
哈希表的每个桶都只能存储 8 个键值对，一旦当前哈希的某个桶超出 8 个，新的键值对就会存储到哈希的溢出桶中
```

```
select 也能够让 Goroutine 同时等待多个 Channel 可读或者可写，在多个文件或者 Channel状态改变之前，select 会一直阻塞当前线程或者 Goroutine。

步骤：
随机生成一个遍历的轮询顺序 pollOrder 并根据 Channel 地址生成锁定顺序 lockOrder；
根据 pollOrder 遍历所有的 case 查看是否有可以立刻处理的 Channel；
如果存在，直接获取 case 对应的索引并返回；
如果不存在，创建 runtime.sudog 结构体，将当前 Goroutine 加入到所有相关 Channel 的收发队列，并调用 runtime.gopark 挂起当前 Goroutine 等待调度器的唤醒；
当调度器唤醒当前 Goroutine 时，会再次按照 lockOrder 遍历所有的 case，从中查找需要被处理的 runtime.sudog 对应的索引；
```

## **Runtime 简介及发展**

## **Runtime 简介**

![img](https://pic3.zhimg.com/80/v2-1be98248ede156b433c0be4af2d5d73e_720w.jpg)

go 的 runtime 代码在 go sdk 的 runtime 目录下,主要有所述的 4 块功能.

## Runtime 的一点个人总结

![img](https://pic1.zhimg.com/80/v2-2c598eec44a5909786868950c5224a6c_720w.jpg)

并行, 纵向多层次, 横向多个 class, 缓存, 缓冲, 均衡.平滑升级

# 平滑升级

服务器在升级时，正在处理的请求需要等待其完成，再退出。Go1.8之后支持该设计。

实现步骤原理：

- 1 fork一个子进程，继承父进程的监听socket
- 2 子进程启动后，接收新的连接，父进程处理原有请求并且不再接收新请求

当系统重启或者升级时，正在处理的请求以及新来的请求该如何处理？

正在处理的请求如何处理：

等待处理完成之后，再推出，Go1.8之后已经支持。比如每来一个请求，计数+1，处理完一个请求，计数-1，当计数为0时，则执行系统升级。

新进来的请求如何处理：

- Fork一个子进程，继承父进程的监听socket（os.Cmd对象中的ExtraFiles参数进行传递，并继承文件句柄）
- 子进程启动成功后，接收新的连接
- 父进程停止接收新的连接，等已有的请求处理完毕，退出，优雅重启成功。

```
package main

import (
	"flag"
	"fmt"
	"os"
	"os/exec"
	"time"
)

var (
	child *bool
)

func startChild(file *os.File) {

	args := []string{"-child"}
	cmd := exec.Command(os.Args[0], args...)
	cmd.Stdout = os.Stdout
	cmd.Stderr = os.Stderr

	cmd.ExtraFiles = []*os.File{file}
	err := cmd.Start()
	if err != nil {
		fmt.Printf("start child failed, err:%v\n", err)
		return
	}

}

func init() {
	//命令行有child选项，则是子进程，没有则是父进程
	child = flag.Bool("child", false, "继承于父进程")
	flag.Parse()
}

func readFromParent() {
	// fd=0 标准输出，=1标准输入，=2标准错误输出，=3 ExtraFiles[0] =4 EAxtraFiles[1]
	f := os.NewFile(3, "")
	count := 0
	for {
		str := fmt.Sprintf("hello, i'child process, write:%d line \n", count)
		count++
		_, err := f.WriteString(str)
		if err != nil {
			fmt.Printf("wrote string failed, err:%v\n", err)
			time.Sleep(time.Second)
			continue
		}
		time.Sleep(time.Second)
	}
}

func main() {

	if child != nil && *child == true {
		fmt.Printf("继承于父进程的文件句柄\n")
		readFromParent()
		return
	}

	//父进程逻辑
	file, err := os.OpenFile("./test_inherit.log", os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0755)
	if err != nil {
		fmt.Printf("open file failed, err:%v\n", err)
		return
	}

	_, err = file.WriteString("parent write one line \n")
	if err != nil {
		fmt.Printf("parent write failed, err:%v\n", err)
	}

	startChild(file)
	fmt.Printf("parent exited")
}
```

runtime/pprof 性能监控

### select() & poll()

首先，通过FD_SET宏函数创建待监控的描述符集合，并将此描述符集合作为select()函数的参数，可以在指定select()函数阻塞时间间隔，于是select()就创建了一个监控对象。

除了普通文件描述符，还可以监控套接字，因为套接字也是文件，所以select()也可以监控套接字文件描述符，例如recv buffer中是否收到了数据，也即监控套接字的可读性，send buffer中是否满了，也即监控套接字的可写性。select()默认最大可监控1024个文件描述符。而poll()则没有此限制。

select()的时间间隔参数分3种：
(1).设置为指定时间间隔内阻塞，除非之前有就绪事件发生。
(2).设置为永久阻塞，除非有就绪事件发生。
(3).设置为完全不阻塞，即立即返回。但因为select()通常在循环结构中，所以这是轮询监控的方式。

当创建了监控对象后，由内核监控这些描述符集合，于此同时调用select()的进程被阻塞(或轮询)。当监控到满足就绪条件时(监控事件发生)，select()将被唤醒(或暂停轮询)，于是select()返回满足就绪条件的描述符数量，之所以是数量而不仅仅是一个，是因为多个文件描述符可能在同一时间满足就绪条件。由于只是返回数量，并没有返回哪一个或哪几个文件描述符，所以通常在使用select()之后，还会在循环结构中的if语句中使用宏函数FD_ISSET进行遍历，直到找出所有的满足就绪条件的描述符。最后将描述符集合通过指定函数拷贝回用户空间，以便被进程处理。

监听描述符集合的大致过程如下图所示，其中select()只是其中的一个环节：

大概描述下这个循环监控的过程：

(1).首先通过FD_ZERO宏函数初始化描述符集合。图中每个小方格表示一个文件描述符。
(2).通过FD_SET宏函数创建描述符集合，此时集合中的文件描述符都被打开，也就是稍后要被select()监控的对象。
(3).使用select()函数监控描述符集合。当某个文件描述符满足就绪条件时，select()函数返回集合中满足条件的数量。图中标黄色的小方块表示满足就绪条件的描述符。
(4).通过FD_ISSET宏函数遍历整个描述符集合，并将满足就绪条件的描述符发送给进程。同时，使用FD_CLR宏函数将满足就绪条件的描述符从集合中移除。
(5).进入下一个循环，继续使用FD_SET宏函数向描述符集合中添加新的待监控描述符。然后重复(3)、(4)两个步骤。

如果使用简单的伪代码来描述：

```
FD_ZERO
for() {
    FD_SET()
    select()
    if(){
        FD_ISSET()
        FD_CLR()
    }
    writen()
}
```

以上所说只是一种需要循环监控的示例，具体如何做却是不一定的。不过从中也能看出这一系列的流程。

以上所说只是一种需要循环监控的示例，具体如何做却是不一定的。不过从中也能看出这一系列的流程。

epoll
epoll比poll()、select()先进，考虑以下几点，自然能看出它的优势所在：

(1).epoll_create()创建的epoll实例可以随时通过epoll_ctl()来新增和删除感兴趣的文件描述符，不用再和select()每个循环后都要使用FD_SET更新描述符集合的数据结构。
(2).在epoll_create()创建epoll实例时，还创建了一个epoll就绪链表list。而epoll_ctl()每次向epoll实例添加描述符时，还会注册该描述符的回调函数。当epoll实例中的描述符满足就绪条件时将触发回调函数，被移入到就绪链表list中。
(3).当调用epoll_wait()进行监控时，它只需确定就绪链表中是否有数据即可，如果有，将复制到用户空间以被进程处理，如果没有，它将被阻塞。当然，如果监控的对象设置为非阻塞模式，它将不会被阻塞，而是不断地去检查。

也就是说，epoll的处理方式中，根本就无需遍历描述符集合。

### 

## Nginx的5种负载均衡算法

### 1. 轮询

轮询是默认的方式，每个请求按时间顺序逐一分配到不同的后端服务器上。如果后台服务器上某一台宕机了，它可以自动剔除。

缺点：可靠性低和负载分配不均衡。适用于图片服务器和静态页面服务器集群。

### 2. 加权轮询（wight）

指定轮询的几率，wight和访问比率成正比，用于后台服务器性能不均匀的情况。

```
upstream linuxidc{       
   server 10.0.0.77 weight=5;       
   server 10.0.0.88 weight=10; 
}复制代码
```

### 3. ip_hash

根据每个请求的ip的hash结果分配，因此每个固定ip能访问到同一个后端服务器，可以解决session问题。

```
upstream favresin{      
    ip_hash;      
    server 10.0.0.10:8080;       
    server 10.0.0.11:8080; 
}复制代码
```

### 4. fair（第三方）

按照后端服务器的响应时间来分配请求，响应时间短的优先分配。

```
 upstream favresin{            
      server 10.0.0.10:8080;       
      server 10.0.0.11:8080;       
      fair; 
}复制代码
```

### 5. url_hash（第三方）

按照访问url的hash结果来分配请求，每个固定的url访问同一个后端服务器。如果后端服务器是缓存时效率高。

```
 upstream resinserver{       
      server 10.0.0.10:7777;       
      server 10.0.0.11:8888;       
      hash $request_uri;       
      hash_method crc32; 
}
例：在upstream中加入hash语句，hash_method是使用的hash算法。
复制代码
```

在upstream模块中，可以通过server命令指定后端服务器的IP地址和端口，同时还可以设置每台后端服务器在负载均衡调度中的状态，

**upstream参数解析**

- upstream可以为每个设备设置状态值
- down：表示当前的server暂时不参与负载
- weight：默认为1，wight越大，负载的权重越大。
- max_fails：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream模块定义的错误。
- fail_timeout：max_fails此失败后，暂停的时间。
- backup：其他所有非backup机器宕或者忙的时候，请求backup的机器。

### 限流方式

- 计数器

- 漏桶；
- 令牌桶。

### Nginx基本数据结构

ngx_pool_t

ngx_array_t

ngx_hash_t

ngx_str_t

ngx_chain_t

ngx_buf_t

ngx_list_t

ngx_queue_t

git revert

# I/O复用模型

1. select

   select的大致工作流程：

   （1）采用**数组**组织文件描述符

   （2）通过遍历数组的方式，监视文件描述符的状态(可读，可写，异常)

   （3）如果没有可读/可写的文件描述符，进程会阻塞等待一段事件，超时就返回

   （4）当有一个可读/可写的文件描述符存在时，进程会从阻塞状态醒来

   （5）进行**无差别轮询**，找出能够操作的I/O流，若处理后，会移除对应的文件描述符

   select的缺点：

   （1）每次调用select，都需要把文件描述符集合从用户空间贝到内核空间，这个开销在I/O流很多时会很大

   （2）同时每次调用select都需要在内核遍历传递进来的所文件描述符数组，这个开销在I/O流很多时也很大

   （3）select支持的文件描述符数量太小了，默认是1024

2. poll

   （1）采用**链表**组织文件描述符

   （2）原理和select一致

   （3）只是解决了支持的文件描述符受限的缺点

   （4）select和poll都是**水平触发**：找到可操作的I/O流并通知进程，但进程本次没有处理，文件描述符没有被移除，下次轮询时依旧会通知

3. epoll

   工作原理：

   （1）**红黑树和就绪链表**，红黑树用于管理所有的文件描述符，就绪链表用于保存有事件发生的文件描述符。

   （2）接收到I/O请求，会在红黑树查找是否存在，不存在就添加到红黑树中，存在则将对应的文件描述符放入就绪链表中

   （3）如果就绪链表为空，进程则阻塞否则遍历就绪链表，并通知应用进程处理文件描述符对应的I/O

   工作模式：

   （1）LT模式(水平触发)：检测到可处理的文件描述符时，通知应用程序，**应用程序可以不立即处理该事件。后续会再次通知**

   （2）ET模式(边缘触发)：检测到可处理的文件描述符时，通知应用程序，**应用程序必须立即处理该事件。如果本次不处理，则后续不再通知**
   
   ### 为什么用红黑树不用 AVL 树

```
AVL是一种高度平衡的二叉树 而每一次对树的修改, 都要 rebalance, 这里的开销会比红黑树大， 所以通常的结果是，维护这种高度*衡所付出的代价比从中获得的效率收益还大，故而实际的应用不多，
更多的地方是用追求局部而不是非常严格整体*衡的红黑树。当然，如果场景中对插入删除不频繁，只是对查找特别有要求，AVL树还是优于红黑树的。
```

## B+树对比红黑树

- 红黑树多用于内部排序，即全放在内存中
- B+树多用于外存上时，B+也被成为一个磁盘友好的数据结构
- 红黑树和平衡二叉树有相同缺点，每个节点存储一个关键词，数据量大时，导致红黑树的深度很深，mysql每次读取时消耗大量io