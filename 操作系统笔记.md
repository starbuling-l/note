# 为什么使用虚拟内存

- 虚拟内存可以结合磁盘和物理内存(可以想象内存和磁盘它都属于一整块虚拟内存)的优势为进程提供看起来速度足够快并且容量足够大的存储（**虚拟内存是操作系统物理内存和进程之间的中间层**，它为进程隐藏了物理内存这一概念 实现缓存机制 无法直接访问内存 都必须通过虚拟内存 即页表进行访问 如果发生缺页中断 如果页表没有虚拟内存当物理内存的对应关系就在页表建立关系 否则将磁盘中的数据加载到内存中，如果内存空间已满进行调页算法进行页面替换）；
- **虚拟内存可以为进程提供独立的内存空间**并引入多层的页表结构将虚拟内存翻译成物理内存，进程之间可以共享物理内存减少开销，也能简化程序的链接、装载以及内存分配过程（可以分配连续的虚拟内存 通过 内存管理单元（MMU）进行分配有可能不连续）；
- 虚拟内存可以控制进程对物理内存的访问 fork 或者进程间共享内存通过复制页表实现，隔离不同进程的访问权限（**读权限、写权限和执行权限**）（比如某些不可读内存，或者操作系统内存的数据结构），提高系统的安全性；

虚拟内存中的虚拟页（Virtual Page，PP）可能处于以下的三种状态 — 未分配（Unallocated）、未缓存（Uncached）和已缓存（Cached），其中未分配的内存页是没有被进程申请使用的，也就是空闲的虚拟内存，不占用虚拟内存磁盘的任何空间，未缓存和已缓存的内存页分别表示仅加载到磁盘中的内存页和已经加载到主存中的内存

虚拟内存可以为正在运行的进程提供独立的内存空间，制造一种每个进程的内存都是独立的假象，在 64 位的操作系统上，每个进程都会拥有 256 TiB 的内存空间，内核空间和用户空间分别占 128 TiB

![image-20210409182603950](C:\Users\liuxingguang\AppData\Roaming\Typora\typora-user-images\image-20210409182603950.png)



比如exec加载可执行文件时只创建页表映射，在执行过程中用到某一页触发缺页才将页从硬盘加载到内存中，按需加载而不是一开始全部从硬盘拷贝到内存里，更有助于理解虚拟地址空间的效果。

那虚拟内存是如何隔离各个进程空间的呢 各个进程会有独立的 Page Table 映射物理内存

go中切片访问元素快是因为内存连续，所以**寻址比较快**吧，物理内存连不连续应该不影响这个结果，访问虚拟内存的时候都需要做一次转换。

我们可以将虚拟内存看作是在磁盘上一片空间，当这片空间中的一部分访问比较频繁时，**该部分数据会以页为单位被缓存到主存中**以加速 CPU 访问数据的性能，虚拟内存利用空间较大的磁盘存储作为『内存』并使用主存储缓存进行加速，**让上层认为操作系统的内存很大而且很快，然而区域很大的磁盘并不快，而很快的内存也并不大**。

# **为什么使用4KB默认设置**

作为内存页大小 4KB 的内存页是上个世纪决定的默认设置（现在在其他操作系统也有实现更大的内存页）（末尾12位代表偏移量，剩下的 36 位会分四组分别表示当前层级在上一层中的索引）目前是四层页表项 如果更小则需要更多层页表项（五层或更多）

- 过小的页面大小会带来较大的页表项增加寻址时 TLB（Translation lookaside buffer）的查找时间和额外开销，但是也会减少程序中的内存碎片，提高内存的利用率；
- 过大的页面大小会浪费内存空间，造成内存碎片，降低内存的利用率（以及多进程共享内存时的写时复制影响额外开销），但是可以减少进程中的页表项以及 TLB 的寻址时间；

# 为什么 CPU 访问硬盘很慢

- CPU 需要通过 I/O 操作访问外部存储中的数据，**编程 I/O**（通过轮询的方式进行写入会占满cpu）、**中断驱动 I/O** （会将一部分任务给IO设备 如果写入好了会通过信号的方式来通知CPU 在之前cpu可以执行其他进程）和 **DMA（Direct Memory Access，直接内存存取）**（将字符全部写入DMA缓存中 有DMA再写入IO设备 **默认方式**） 几种方式都会带来额外开销并占用较多的 CPU 时间；
- 机械硬盘会通过机械结构访问其中存储的数据，每一次硬盘的随机 I/O 都需要执行队列、寻道、旋转和转移数据几个过程，大约需要消耗 10ms 的时间，尽量属于顺序 I/O 可以优化好几个数量级，SSD寻址不会通过机械设备读取由电路完成会快很多；

- 写入到硬盘上的数据一定会被持久存储，不会丢失吗？

  数据先落到Page Cache 然后调用fsync（）才能写道硬盘上

- 内存中的数据为什么在断电重启之后就会被清空？

  靠通电保持电位（数据）断电就重置了 硬盘通过磁力的方式进行持久化

# 为什么 NUMA 会影响程序的延迟

非一致性内存访问（Non-Uniform Memory Access、NUMA）是一种计算机内存的设计方式[1](https://draveness.me/whys-the-design-numa-performance#fn:1)，与 NUMA 相对的还有一致性内存访问（Uniform Memory Access、UMA），也被称作对称多处理器架构（Symmetric Multi-Processor、SMP），早期的计算机都会使用 SMP，然而现代的多数计算机都会采用 NUMA 架构管理 CPU 和内存资源。		多核架构限制在于前端总线 北桥 内存总线

![image-20210412172453579](C:\Users\liuxingguang\AppData\Roaming\Typora\typora-user-images\image-20210412172453579.png)

将内存与cpu绑定划分节点

![image-20210412172531813](C:\Users\liuxingguang\AppData\Roaming\Typora\typora-user-images\image-20210412172531813.png)

- NUMA 引入了本地内存和远程内存，**CPU 访问本地内存的延迟会小于访问远程内存**；
- NUMA 的  以及**CPU分配策略**  **内存分配策略**与内存回收策略结合时会可能会导致 Linux 的频繁交换分区（Swap）进而影响系统的稳定性，交换分区影响性能通过分配合理的策略可以优化 例如节点平均分配内存；

我们当然更希望**主机上的所有 CPU 都能够快速地访问全部的内存**，但是硬件的限制导致我们无法实现这么理想的情况，而 NUMA 可能是 CPU 架构发展的必然方向，通过将 CPU 和内存资源分组降低总线的压力，让单个主机容纳很多的 CPU。

# 为什么 HugePages 可以提升数据库性能

- HugePages （默认是2MB内存页 更大可以达到1GB）可以降低内存页面的管理开销，它可以减少进程中的页表项、提高 TLB 缓存的命中率和内存的访问效率；
- HugePages 可以锁定内存，禁止操作系统的内存交换和释放，不会被交换到磁盘上为其它请求让出内存；
- 适用于特定场景 如数据库 Hadoop全家桶等 对于普通web服务器可能是负担 同样在redis fork进行写时复制同样 在改动数据比较小HugePages会带来更大的开销

# 为什么 Linux 需要 Swapping

**物理内存和硬盘上的交换分区组成了操作系统上可用的虚拟内存**

先在空闲页列表中查找是否有可用的页面，如果不存在可用页面进行分配新的内存页

Linux 在**内存也不足**时获取内存的几个常见方法**：内存压缩、直接回收以及触发内存不足错误杀掉部分进程。**

应用程序在启动阶段使用的大量内存在启动后往往都不会使用，通过后台运行的守护进程，我们可以将这部分只使用一次的内存交换到磁盘上为其他内存的申请预留空间。

**kswapd会在空闲内存低于一定水位时，回收内存页中的空闲内存保证系统中的其他进程可以尽快获得申请的内存**

当系统内存不足时应该立即触发内存不足（Out of memory、OOM）并杀掉进程，但是 Swapping 其实为系统管理员提供了另外一种选择，利用磁盘的交换空间避免程序被直接退出，以**降低服务质量的代价换取服务的部分可用性**。Linux 中的 Swapping 机制主要是为**内存不足**和**内存闲置**两种常见的情况存在的 （**在可用性要求较高的场合，使用降级而不是停止服务的方式比较合适。**）

- Swapping 可以直接将进程中使用相对较少的页面换出内存：当系统需要的内存超过了可用的物理内存时，内核会将内存中不常使用的内存页交换到磁盘上为当前进程让出内存，保证正在执行的进程的可用性；
- Swapping 可以将进程中的闲置页面换出内存：应用程序在启动阶段使用的大量内存在启动后往往都不会使用，通过后台运行的守护进程，我们可以将这部分只使用一次的内存交换到磁盘上为其他内存申请预留空间；

**swapping和你之前的文章 `为什么 Linux 需要虚拟内存` 中的页面交换不是一个东西**

# 为什么基础服务不应该高可用

1. 在足够长的时间中，任何服务都没法保证 100% 可用，100% 可用更像是一个危险的承诺，一旦默认了这个假设就不利于我们构建高可用的服务；
2. 边际成本是提升可用性时必须要考虑的因素，作为服务提供商必须要衡量提升可用性的成本和收益，而过高或者过低的可用性都会降低总体的收益；
3. 服务的高可用从来都不来源于单一的依赖，只有使用更多异构的副本和组件才能尽可能保证服务的稳定；

例如：

- 物理机不同：部署在不同机器上的 Redis 服务；
- 协议和代码不同：本地部署的 Redis 和 memcached 服务；
- 服务提供商不同：谷歌云和 AWS 的 Redis 服务；
- 地理位置不同：北京和上海的机房中的 Redis 服务；
- …

如果可用性高于约定的 SLA，**很多服务提供商会在一个可用性计算周期结束之前故意动触发服务的宕机**

SRE: Google 运维解密 这本书也说了, 故意宕机一方面是让用户明白这些东西不是百分百可靠的, 然后通过自己的手段解决; 另一方面是为了不让用户的预期过高.

# 为什么使用通信来共享内存

『不要通过共享内存来通信，我们应该使用通信来共享内存』

​	channel底层同样使用的是共享内存和锁 更高级的抽象

![image-20210413110429966](C:\Users\liuxingguang\AppData\Roaming\Typora\typora-user-images\image-20210413110429966.png)

1. 首先，使用发送消息来同步信息相比于直接使用共享内存和互斥锁是一种更高级的抽象，使用更高级的抽象能够为我们在程序设计上提供更好的封装，让程序的逻辑更加清晰；
2. 其次，消息发送在解耦方面与共享内存相比也有一定优势，我们可以将线程的职责分成生产者和消费者，并**通过消息传递的方式将它们解耦，不需要再依赖共享内存**；
3. **最后，Go 语言选择消息发送的方式，通过保证同一时间只有一个活跃的线程能够访问数据，能够从设计上天然地避免线程竞争和数据冲突的问题；**

![image-20210413110902662](C:\Users\liuxingguang\AppData\Roaming\Typora\typora-user-images\image-20210413110902662.png)

不推荐或者禁止使用外键重启可能会出现主键问题 

# 为什么 MySQL 的自增主键不单调也不连续

> 主键连续的意义在哪里？充分利用防止用完？

连续的key可以保证b+树写索引的时候尽量顺序写，不会导致page页面分裂

- MySQL 5.7 版本之前在内存中存储 `AUTO_INCREMENT` 计数器，实例重启后会根据表中的数据重新设置，在删除记录后重启就可能出现重复的主键，该问题在 8.0 版本使用重做日志解决，保证了主键的单调性；
- MySQL 插入数据获取 `AUTO_INCREMENT` 时不会使用事务锁，而是会使用互斥锁，并发的插入事务可能出现部分字段冲突导致插入失败，想要保证主键的连续需要串行地执行插入语句；

> 有个问题想问下，关于图 3 - 5.7 版本之前的 AUTO_INCMRENT
>
> 那图上半部的意思是更新 `executions` 之后也会影响 `trades` 表的 `AUTO_INCMRENT` 的？

不是，这里的意思是 executions 表中的记录引用了 trades 表中 id 为 10 的记录，但是随后 trades 表中的记录被删除了，我们使用相同的 id 创建了新的记录，executions 表完全不知道，**它以为自己引用的还是过去的记录**。

- 不使用外键牺牲了数据库中数据的一致性，但是却能够减少数据库的负载；
- 模拟外键将一部分工作移到了数据库之外，我们可能需要放弃一部分一致性以获得更高的可用性，但是为了这部分可用性，我们会付出更多的研发与维护成本，也增加了与数据库之间的网络通信次数；
- 使用外键保证了数据库中数据的一致性，也将全部的计算任务全部交给了数据库；

大团队也有更多的时间和精力去设计其他的方案，例如：分布式的关系型数据库。

使用外键时可能遇到的问题：

- `RESTRICT` 外键会在更新和删除关系表中的数据时对外键约束的合法性进行检查，保证外键不会引用到不存在的记录；
- `CASCADE` 外键会在更新和删除关系表中的数据时触发对关联记录的更新和删除，在数据量较大的数据库中可能会有数量级的放大效果；

话说现在接触到的系统里都很少直接删除行数据了，都是用 `deleted` 或者 `deleted_at` 做归档化。

当用户再次启动数据库进程时，还能够立刻通过查询回滚日志将之前未完成的事务进行回滚，这也就需要回滚日志必须先于数据持久化到磁盘上，是我们需要先写日志后写数据库的主要原因。

- **Undo** ：将所有没有提交的事务恢复到提交前的状态，因而 `(T, x, v)` 中 v 记录的是修改前的值，便于恢复。
- **Redo** ：将所有已提交的事务（已写入 log，但因为崩溃数据未写入）重新写入，因而 `(T, x, v)` 中 v 记录的是修改后的值，便于重做。

**并发控制通过读写锁和MVCC（多版本控制）结合**

MVCC 在于乐观锁结合时的实现上有一些不同，最终实现的叫做多版本时间戳排序协议（Multiversion Timestamp Ordering），在这个协议中，所有的事务在执行之前都会被分配一个唯一的时间戳，每一个数据项都有读写两个时间戳：

![image-20210415145948509](C:\Users\liuxingguang\AppData\Roaming\Typora\typora-user-images\image-20210415145948509.png)

事务发出了一个读请求，数据库直接将最新版本的数据返回，不会被任何操作阻塞，而写操作在执行时，事务的时间戳一定要大或者等于数据行的读时间戳，否则就会被回滚。

死锁：两个持有锁的资源相互请求 预防死锁通过抢占和回滚





一个 SQL 执行的很慢，我们要分两种情况讨论：

1、大多数情况下很正常，偶尔很慢，则有如下原因

(1)、数据库在刷新脏页（内存不够 或者 内存页空闲 系统空闲），例如 redo log 写满了需要同步到磁盘。（先写redo log 再由redo log更新脏页）

**当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。**

(2)、执行的时候，遇到锁，如表锁、行锁。

2、这条 SQL 语句一直执行的很慢，则有如下原因。

(1)、没有用上索引：例如该字段没有索引；由于对字段进行运算、函数操作导致无法用索引。

(2)、数据库选错了索引。（用保存主键信息的辅助索引最后走的主键查询）

**规范：**

尽量使用Innodb作为存储引擎

避免使用text类型 枚举类型（效率低要使用额外操作）

尽可能把所有列定义为 NOT NULL（占用空间，null比较需要特殊处理）

使用预编译

不使用select  *

不要join太多表

尽量不使用外键（影响父表和子表的写操作从而降低性能）

不使用随机排序

大 sql 拆分

最常见的分区方法就是按照时间进行分区 

MySQL支持范围分区（RANGE），列表分区（LIST），哈希分区（HASH）以及KEY分区 **partion** 命令 

分库（读写分离）分表垂直拆分水平拆分 简单的通过%分表数

从锁定资源的角度来看，MySQL 中的锁分为：

- **表级锁**
- **行级锁**
- **页面锁**

表级锁：对整张表加锁。开销小，加锁快;不会出现死锁;锁定粒度大，发生锁冲突的概率最高，并发度最低。

行级锁：对某行记录加锁。开销大，加锁慢;会出现死锁;锁定粒度最小，发生锁冲突的概率最低，并发度也最高。

页面锁：开销和加锁时间界于表锁和行锁之间;会出现死锁;锁定粒度界于表锁和行锁之间，并发度一般。

在实际开发过程中，主要会使用到表级锁和行级锁两种

- MyISAM 存储引擎，它不支持事务、表锁设计，支持全文索引，主要面向一些在线分析处理(OLAP)数据库应用。说白了主要就是查询数据，对数据的插入，更新操作比较少。

### 使用 Explain 进行分析

Explain 用来分析 SELECT 查询语句，开发人员可以通过分析 Explain 结果来优化查询语句。

比较重要的字段有：id（执行顺序从上至下）

- select_type : 查询类型，有简单查询、联合查询、子查询等
- key : 使用的索引
- rows : 扫描的行数

# (2) explain参数详解

| id   | Columns       | JSON Name     | Meaning                                           |
| :--- | :------------ | :------------ | :------------------------------------------------ |
| 1    | id            | select_id     | 每个select子句的标识id                            |
| 2    | select_type   | None          | select语句的类型                                  |
| 3    | table         | table_name    | 当前表名                                          |
| 4    | partitions    | partitions    | 匹配的分区                                        |
| 5    | type          | access_type   | 当前表内访问方式 join type                        |
| 6    | possible_keys | possible_keys | 可能使用到的索引                                  |
| 7    | key           | key           | 经过优化器评估最终使用的索引                      |
| 8    | key_len       | key_length    | 使用到的索引长度                                  |
| 9    | ref           | ref           | 引用到的上一个表的列                              |
| 10   | rows          | rows          | rows_examined，要得到最终记录索要扫描经过的记录数 |
| 11   | filtered      | filtered      | 按表条件过滤行的百分比                            |
| 12   | Extra         | None          | 额外的信息说明                                    |

### 索引的优点(中大型表) （辅助索引和主键索引）最左边前缀

- 大大减少了服务器需要扫描的数据行数。
- 帮助服务器避免进行排序和分组，以及避免创建临时表（B+Tree 索引是有序的，可以用于 ORDER BY 和 GROUP BY 操作。临时表主要是在排序和分组过程中创建，不需要排序和分组，也就不需要创建临时表）。
- 将随机 I/O 变为顺序 I/O（B+Tree 索引是有序的，会将相邻的数据都存储在一起）。

Timestamp记录时间效率高还各种兼容

（通过簇拥索引组织数据 不能为null） 多个索引（PRIMARY KEY） 一个表只能有一个主键

limit优化考虑加索引 like 利用**索引条件下推ICP**优化

**很长的字段，想做索引我们怎么去优化他呢？**

因为存在一个磁盘占用的问题，索引选取的越长，占用的磁盘空间就越大，相同的数据页能放下的索引值就越少，搜索的效率也就会越低。

我当时就回答了一个hash，把字段hash为另外一个字段存起来，每次校验hash就好了，hash的索引也不大。

我们都知道只要区分度过高，都可以，那我们可以采用倒序，或者删减字符串这样的情况去建立我们自己的区分度，不过大家需要注意的是，调用函数也是一次开销哟，这点当时没注意。

就比如本来是www.aobing@qq,com 其实前面的`www.`基本上是没任何区分度的，所有人的邮箱都是这么开头的，你一搜一大堆出来，放在索引还浪费内存，你可以substring()函数截取掉前面的，然后建立索引。

我们所有人的身份证都是区域开头的，同区域的人很多，那怎么做良好的区分呢？REVERSE（）函数翻转一下，区分度可能就高了。

这些操作都用到了函数，我就说一下函数的坑。

# 为什么 OLAP 需要列式存储

(主要是记录存取)

- 列式存储可以满足快速读取特定列的需求，在线分析处理往往需要在上百列的宽表中读取指定列分析，而传统的行式存储在分析数据时往往需要使用索引或者遍历整张表，带来了非常大的额外开销；
- 列式存储就近存储同一列的数据（例如字符串 数字等都存取在同一列），使用压缩算法可以得到更高的压缩率，减少存储占用的磁盘空间，虽然带来了 CPU 时间的额外开销，但是节省的 I/O 时间比带来的额外开销更多；

# 为什么比特币可以防篡改

- 非对称加密可以保证攻击者无法伪造账户所有者的签名；
- 共识算法可以保证网络中的历史交易不会被攻击者替换；

## 分布式一致性

在一个分布式系统中，如何保证集群中所有节点中的数据完全相同并且能够对某个提案（Proposal）达成一致是分布式系统正常工作的核心问题，而共识算法就是用来保证分布式系统一致性的方法。

着节点数量的增加，节点失效、故障或者宕机就变成了一件非常常见的事情，解决分布式系统中的各种边界条件和意外情况也增加了解决分布式一致性问题的难度。节点之间的网络通信收到干扰甚至阻断以及分布式系统的运行速度的差异都是解决分布式系统一致性所面临的难题。

异步的网络模型中，所有的节点由于没有时钟仅仅能根据接收到的消息作出判断，这时完全不能同时保证一致性、可用性和分区容错性，每一个系统只能在这三种特性中选择两种。

最终一致性允许多个节点的状态出现冲突，但是所有能够沟通的节点都能够在有限的时间内解决冲突，从不一致的状态恢复到一致，这里列出的两个条件比较重要，一是节点直接可以**正常通信**，二是冲突需要在**有限的时间**内解决，只有在这两个条件成立时才能达到最终一致性。

拜占庭将军问题是 分布式领域中最复杂、最严格的容错模型。

在该模型下，系统不会对集群中的节点做任何的限制，它们可以向其他节点发送随机数据、错误数据，也可以选择不响应其他节点的请求，

不要浪费时间去为异步分布式系统设计在任意场景上都能够实现共识的算法，异步系统完全没有办法保证能在有限时间内达成一致，在这里作者并不会尝试去证明 FLP 不可能定理

Paxos 和 Raft 是目前分布式系统领域中两种非常著名的解决一致性问题的共识算法，两者都能解决分布式系统中的一致性问题目前的**完备的**共识算法包括 Raft 本质上都是 Paxos 的变种。